{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pandas numpy scikit-learn\n"
      ],
      "metadata": {
        "id": "kPlEu1Snq2bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9MC3P8RUxLN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "url = 'https://drive.google.com/uc?id=1O_NwpJT-8xGfU_-3llUl2sgPu0xllOrX&export=download'\n",
        "data = pd.read_csv(url)\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target variable\n",
        "X = data.drop(columns=['Price'])\n",
        "y = data['Price']\n"
      ],
      "metadata": {
        "id": "GZeQFbEHq-Uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "RCA0C0OksLzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Initialize KFold\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "betas = []\n",
        "r2_scores = []\n",
        "\n",
        "# Iterate through each fold\n",
        "for train_index, test_index in kf.split(X_scaled):\n",
        "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Fit the model\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict values\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate R2 score\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "    betas.append(model.coef_)\n",
        "\n",
        "# Find the best beta matrix (with maximum R2 score)\n",
        "best_index = np.argmax(r2_scores)\n",
        "best_beta = betas[best_index]\n",
        "best_r2 = r2_scores[best_index]\n",
        "\n",
        "print(f\"Best R2 Score: {best_r2}\")\n",
        "print(f\"Best Beta Matrix: {best_beta}\")\n"
      ],
      "metadata": {
        "id": "IP8K7jxnsOwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into train (70%) and test (30%)\n",
        "X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train the final model\n",
        "final_model = LinearRegression()\n",
        "final_model.fit(X_train_final, y_train_final)\n",
        "\n",
        "# Predict and calculate R2 score on the test set\n",
        "final_predictions = final_model.predict(X_test_final)\n",
        "final_r2_score = r2_score(y_test_final, final_predictions)\n",
        "\n",
        "print(f\"Final R2 Score on Test Data: {final_r2_score}\")\n"
      ],
      "metadata": {
        "id": "9nOk_iXQsdA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DH6DOeiVve9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#q2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "url = 'https://drive.google.com/uc?id=1O_NwpJT-8xGfU_-3llUl2sgPu0xllOrX'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop(columns=['Price'])\n",
        "y = data['Price']\n",
        "\n",
        "# Scale the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training (56%), validation (14%), and test (30%) sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.44, random_state=42)  # 44% for validation and test\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.68, random_state=42)  # 30% test, 14% validation\n",
        "\n",
        "# Function to perform gradient descent\n",
        "def gradient_descent(X, y, learning_rate, iterations):\n",
        "    m, n = X.shape\n",
        "    beta = np.zeros(n)\n",
        "    for _ in range(iterations):\n",
        "        predictions = X.dot(beta)\n",
        "        errors = predictions - y\n",
        "        beta -= (learning_rate / m) * (X.T.dot(errors))\n",
        "    return beta\n",
        "\n",
        "# Learning rates\n",
        "learning_rates = [0.001, 0.01, 0.1, 1]\n",
        "iterations = 1000\n",
        "\n",
        "best_beta = None\n",
        "best_r2_val = -np.inf\n",
        "best_r2_test = -np.inf\n",
        "\n",
        "# Train and evaluate for each learning rate\n",
        "for lr in learning_rates:\n",
        "    # Perform gradient descent\n",
        "    beta = gradient_descent(X_train, y_train, lr, iterations)\n",
        "\n",
        "    # Predict on validation and test sets\n",
        "    val_predictions = X_val.dot(beta)\n",
        "    test_predictions = X_test.dot(beta)\n",
        "\n",
        "    # Compute R² scores\n",
        "    r2_val = r2_score(y_val, val_predictions)\n",
        "    r2_test = r2_score(y_test, test_predictions)\n",
        "\n",
        "    print(f\"Learning Rate: {lr}\")\n",
        "    print(f\"Beta Coefficients: {beta}\")\n",
        "    print(f\"Validation R² Score: {r2_val}\")\n",
        "    print(f\"Test R² Score: {r2_test}\")\n",
        "\n",
        "    # Update best coefficients if validation R² is higher\n",
        "    if r2_val > best_r2_val:\n",
        "        best_r2_val = r2_val\n",
        "        best_r2_test = r2_test\n",
        "        best_beta = beta\n",
        "\n",
        "# Display the best results\n",
        "print(\"\\nBest Model:\")\n",
        "print(f\"Best Beta Coefficients: {best_beta}\")\n",
        "print(f\"Best Validation R² Score: {best_r2_val}\")\n",
        "print(f\"Best Test R² Score: {best_r2_test}\")\n"
      ],
      "metadata": {
        "id": "QgeBKkXpvg8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\"\n",
        "column_names = [\"symboling\", \"normalized_losses\", \"make\", \"fuel_type\", \"aspiration\",\n",
        "                \"num_doors\", \"body_style\", \"drive_wheels\", \"engine_location\",\n",
        "                \"wheel_base\", \"length\", \"width\", \"height\", \"curb_weight\",\n",
        "                \"engine_type\", \"num_cylinders\", \"engine_size\", \"fuel_system\",\n",
        "                \"bore\", \"stroke\", \"compression_ratio\", \"horsepower\", \"peak_rpm\",\n",
        "                \"city_mpg\", \"highway_mpg\", \"price\"]\n",
        "\n",
        "data = pd.read_csv(url, names=column_names)\n",
        "data.replace('?', np.nan, inplace=True)\n",
        "\n",
        "# Step 2: Handle missing values\n",
        "# Convert relevant columns to numeric\n",
        "data[numeric_cols] = data[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Fill NaN values with the mean for numeric columns\n",
        "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
        "data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].mean())\n",
        "\n",
        "# Drop rows where 'price' is NaN\n",
        "data.dropna(subset=['price'], inplace=True)\n",
        "\n",
        "# Step 3: Convert non-numeric values\n",
        "# (i) Convert num_doors and num_cylinders\n",
        "data['num_doors'].replace({'two': 2, 'four': 4}, inplace=True)\n",
        "data['num_doors'] = pd.to_numeric(data['num_doors'], errors='coerce')\n",
        "\n",
        "data['num_cylinders'].replace({'two': 2, 'three': 3, 'four': 4, 'five': 5, 'six': 6, 'eight': 8}, inplace=True)\n",
        "data['num_cylinders'] = pd.to_numeric(data['num_cylinders'], errors='coerce')\n",
        "\n",
        "# (ii) Dummy encoding for body_style and drive_wheels\n",
        "data = pd.get_dummies(data, columns=['body_style', 'drive_wheels'], drop_first=True)\n",
        "\n",
        "# (iii) Label encoding for make, aspiration, engine_location, and fuel_type\n",
        "label_cols = ['make', 'aspiration', 'engine_location', 'fuel_type']\n",
        "label_encoder = LabelEncoder()\n",
        "for col in label_cols:\n",
        "    data[col] = label_encoder.fit_transform(data[col])\n",
        "\n",
        "# (iv) Replace fuel_system values\n",
        "data['fuel_system'] = data['fuel_system'].apply(lambda x: 1 if 'pfi' in str(x) else 0)\n",
        "\n",
        "# (v) Replace engine_type values\n",
        "data['engine_type'] = data['engine_type'].apply(lambda x: 1 if 'ohc' in str(x) else 0)\n",
        "\n",
        "# Step 4: Prepare input features and scale\n",
        "X = data.drop(columns=['price']).astype(float)  # Features\n",
        "y = data['price'].astype(float)  # Target variable\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Step 5: Train and test linear regression model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate\n",
        "y_pred = lin_reg.predict(X_test)\n",
        "initial_r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Initial R² Score: {initial_r2}\")\n",
        "\n",
        "# Step 6: Apply PCA\n",
        "pca = PCA(n_components=0.95)  # Keep 95% of variance\n",
        "X_pca = pca.fit_transform(X_train)\n",
        "\n",
        "# Train a new model with PCA-reduced data\n",
        "lin_reg_pca = LinearRegression()\n",
        "lin_reg_pca.fit(X_pca, y_train)\n",
        "\n",
        "# Transform the test set\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# Make predictions and evaluate\n",
        "y_pred_pca = lin_reg_pca.predict(X_test_pca)\n",
        "pca_r2 = r2_score(y_test, y_pred_pca)\n",
        "print(f\"R² Score after PCA: {pca_r2}\")\n"
      ],
      "metadata": {
        "id": "_ZkBXZCZ4LiR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}